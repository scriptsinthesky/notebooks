{
 "metadata": {
  "name": "",
  "signature": "sha256:2099bae09b4aaaf73bcff169c8001320ae5ca774c48b52a0a1592aea9d7e2c90"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<figure>\n",
      "  <IMG SRC=\"https://raw.githubusercontent.com/mbakker7/exploratory_computing_with_python/master/tudelft_logo.png\" WIDTH=250 ALIGN=\"right\">\n",
      "</figure>\n",
      "\n",
      "# Exploratory Computing with Python\n",
      "*Developed by Mark Bakker*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Statistics Notebook 2: Continuous random variables\n",
      "In this notebook we deal with continuous distributions. We start with analyzing data that we generate ourselves, and we will consider real data at the end of this Notebook.\n",
      "\n",
      "The most common probability distribution is probably (no pun intended) the Normal distribution. Random numbers from a Normal distribution may be generated with the `standard_normal` function in the `random` subpackage of `numpy`. The numbers are drawn from a \"standard\" Normal distribution, which means a Normal distribution with mean 0 and standard deviation 1. The mean and standard deviation of a dataset can be computed with the functions `mean` and `std` of the `numpy` package."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy.random as rnd\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = rnd.standard_normal(100)  # Array with 100 values\n",
      "print 'mean of data: ', np.mean(data)\n",
      "print 'standard deviation of data: ', np.std(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that the mean and standard deviation are not exactly equal to 0 and 1, respectively. These are, after all, only estimates of the true underlying mean and standard deviation. These estimates are called the sample mean and sample standard deviation (of 100 numbers drawn from a Normal distribution). Run the above code several times. Each time, a new set of 100 random numbers is drawn, with a slightly different mean and standard deviation. We'll get back to that later. \n",
      "\n",
      "To generate numbers from a Normal distribution with mean $\\mu$ and standard deviation $\\sigma$, draw numbers from the standard Normal distribution, multiply all values by $\\sigma$ and then add $\\mu$ (see [here](http://www.statlect.com/ucdnrm1.htm))."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mu = 6.0\n",
      "sig = 2.0\n",
      "data = sig * rnd.standard_normal(100) + mu\n",
      "print 'mean of data: ', np.mean(data)\n",
      "print 'standard deviation of data: ', np.std(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Histograms\n",
      "One of the first things to do, when you obtain a new data set, is to look at the data. One way to do that is to draw a histogram. For a histogram, you count how many data points fall within a certain interval. For example, how many data points are within 5 and 6. These intervals are called bins. The bar graph of the number of data points in each bin is called a histogram. The function to compute and plot a histogram is called `hist` and is part of the `matplotlib` package. The simplest way of plotting a histogram is to let `hist` decide what bins to use; the default number of bins is `nbin=10`; `hist` even figures out where to put the limits of the bins. The `hist` function creates a histogram graph and returns a tuple of three items. The first item is an array of length `nbin` with the number of data points in each bin. The second item is an array of length `nbin+1` with the limits of the bins. The third item is a list of objects that represent the bars of the histogram; we won't use this last item here. Note that with a dataset of 100 points, the histogram doesn't look too much like the typical bell-shaped curve of a Normal distribution, even though the data points are actually drawn from a real Normal distribution. Run the code below several times to see how it changes with a new random set of 100 data points."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mu = 6.0\n",
      "sig = 2.0\n",
      "data = sig * rnd.standard_normal(100) + mu\n",
      "a = plt.hist(data)\n",
      "plt.xlabel('bins')\n",
      "plt.ylabel('number of data points')\n",
      "print 'number of data points in each bin: ',a[0]\n",
      "print 'limits of the bins: ',a[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As you can see from the previous example, the limits of the bins are not chosen as nice numbers: `hist` takes the minimum and maximum value of the data and divides it in `nbin` equal intervals. Alternatively, you can specify the number of bins with the `bins` keyword, and the range (minimum and maximum limits of the bins) with the `range` keyword. If data values are outside this range (such as outliers), they are ignored. In the code below, 12 bins are chosen equally spaced from 0 to 12. Note that we use the same date as for the graph above, but by simply choosing different bins the histogram looks quite different."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = plt.hist(data, bins = 12, range = (0,12))\n",
      "print 'number of data points in each bin: ',a[0]\n",
      "print 'limits of the bins: ',a[1]\n",
      "plt.xlabel('bins')\n",
      "plt.ylabel('number of data points')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A line representing the underlying normal distribution may be added as follows. First import the `norm` class from the `scipy.stats` package. Then call the `norm.pdf` function (pdf stands for probability density function) to compute the values of the normal distribution given three arguments: the $x$ values where to compute the normal distribution, the mean, and the standard deviation. Let's add the normal distribution to the histogram we just created. The one thing we have to change in the histogram is the vertical axis. In the graph above, the vertical axis shows the number of data points. We need to normalize this so that the vertical axis gives the probability that a data point lies in a bin. The histogram may be normalized by specifying the `normed = True` keyword:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats import norm\n",
      "a = plt.hist(data, bins = 12, range = (0,12), normed=True)\n",
      "x = np.linspace(0,12,100)\n",
      "y = norm.pdf(x,6,2) # mu=6, sig=2\n",
      "plt.plot(x,y,'r')\n",
      "plt.xlabel('bins')\n",
      "plt.ylabel('probability')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Exercise 1: <a name=\"back1\"></a>First histogram\n",
      "Generate 1000 random numbers from a Normal distribution with mean 100 and standard deviation 10. Compute and print to the screen the mean and standard deviation of your data. Create two graphs above each other using the `subplot` command (use `help(subplot)` if you forgot how to do that). In the top graph, plot a histogram using 20 bins going from 50 to 150. Note that with this size of a data set (1000 data points), the histogram starts to look a lot more like the typical bell-shaped curve of a Normal distribution. Add a red line representing the probability density function of the underlying normal distribution to the graph. In the bottom graph, draw a histogram of the cumulative distribution function, by setting the keyword `cumulative = True` (see `help(hist)` for details). For the latter graph, it may also be nice to use the keywords `histtype = 'step'` and `align='right'`. Add a red line representing the cumulative distribution function of the underlying normal distribution to the graph using the `norm.cdf` function, which works the same as the `norm.pdf` function but computes the cumulative distribution function (cdf). Finally, make sure the limits along the horizontal axis are the same for both graphs. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#ex1answer\">Answers to Exercise 1</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Percentiles\n",
      "Another useful description of a dataset are the percentiles or quantiles. For this we consider the ordered data, that is, we order the datapoints in ascending order (so the first datapoint is the minimum of the data and the last datapoint is the maximum). The 25 percentile is the data point in the ordered data such that 25% of the data is below this datapoint (and thus 75% is above this datapoint). The percentiles of a dataset are commonly referred to as the 'empirical percentiles' as they are the percentiles of the dataset, not of the underlying distribution. The 50 empirical percentile is equivalent to the median of the data. Common intervals to look at are the 50% region around the median (also called the interquartile range or IQR), which runs from the 25 empirical percentile to the 75 empirical percentile, and the 95% region, which runs from the 2.5 empirical percentile to the 97.5 empirical percentile. Percentiles of a dataset may be computed with the `percentile` function in the `numpy` package. The first argument is the data, the second argument is a list of percentiles:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = 2.0 * rnd.standard_normal(100) + 10.0  # mu = 10, sigma = 2, 100 points\n",
      "lower, median, upper = np.percentile(data, [2.5, 50, 97.5])\n",
      "print '2.5 percentile: ',lower\n",
      "print '50 percentile: ',median\n",
      "print '97.5 percentile: ',upper\n",
      "print '95% interval: ',lower,' to ',upper"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Theoretical percentiles of a given distribution may be computed with the `interval` function, which gives the interal around the median. For example, the 95% region for the standard normal distribution is given by"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "norm.interval(0.95)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This means that the 95 percentile runs from -1.96 times the standard deviation to +1.96 the standard deviation. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Expercise 2. <a name=\"back2\"></a>Lower and upper quartile\n",
      "Generate 1000 data points from a normal distribution with a mean of 20 and a standard deviation of 4. Compute the interquartile range (25%-75% range). Compute the theoretical value of the interquartile range and compare it to the interquartile range of the data. Draw a histogram of the cumulative distribution. Add red vertical lines to your graph for the 25 and 75 empirical percentiles of the data, and black vertical lines for the true 25 and 75 percentiles. Vertical lines that span the graph may be added with the `axvline` function of the `matplotlib` package, which takes the $x$ value of the line as an argument. To specify the color of the vertical line, use the `color` keyword argument."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#ex2answer\">Answers to Exercise 2</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Box-whisker plots\n",
      "Box-whisker plots (also simply referred to as boxplots) are a way to visualize the level and spread of the data. By simply looking at a boxplot, you can see whether the data is symmetric or not, and how widely the data are spread. A box-whisker plot may be created with the `boxplot` function in the `matplotlib` package as follows"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rnd.seed(10)\n",
      "data = 2.0 * rnd.standard_normal(500) + 10.0  # mu = 10, sigma = 2, 500 points\n",
      "a = plt.boxplot(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `boxplot` function creates the graph and returns a lot of stuff such as 'boxes', 'caps', etc. These latter ones are handles to the different features of the graph; we will not use them here. What you see in the graph is a red line at the median of the data. The blue box spans the IQR ranging from the lower quartile (25%) to the upper quartile (75%). The whiskers are the black lines that are connected to the 50% box with the blue dashed lines. They extend to the most extreme data point within the `whis*IQR` data range, where the default value of `whis` is 1.5. Any data points falling outside the whiskers are potential outliers and are plotted as crosses. In this case there are 5 points outside the whiskers, but none are outliers. They were, after all, drawn from a Normal distribution!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Pandas\n",
      "All the techniques described in this Notebook can also be done with the `pandas` package. `pandas` is often much easier as it has a lot more functionality, it can handle missing values (`NaN` values, for example), and the plots are pretty by default.\n",
      "\n",
      "The `read_csv` function of `pandas` may be used to read data from a file and store it in a `DataFrame` (see Notebook 5). A `DataFrame` may also be created from scratch. First, the `pandas` package is imported and called `pd`. Then an empty `DataFrame` is created and values are added to two columns by drawing from two different normal distributions; the columns are called `test1` and `test2`. The  `describe` function of `pandas` gives a nice summary of the data, including the number of values, mean, standard deviation, min, 25%, 50%, 75%, and max values. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "data = pd.DataFrame()\n",
      "data['test1'] = 2 * rnd.standard_normal(100) + 3\n",
      "data['test2'] = 1 * rnd.standard_normal(100) + 5\n",
      "data.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Values such as `mean` or `max` may be obtained for the entire `DataFrame` or for one column at a time. The percentiles may be obtained with the `quantile` function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'minimum of test1:', data.test1.min()\n",
      "print 'standard deviation of the DataFrame:', data.std()\n",
      "print '5% and 95% precentiles of test2:'\n",
      "print data.test2.quantile([0.05,0.95])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The histogram of the data in the two columns may be created with the `hist` function of `pandas`. Notice that the `sharex` keyword is set to `True` so that the horizontal axis has the same length for both histograms."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.hist(sharex=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Missing data\n",
      "Real data often contains missing values. Every database has its own way of treating missing values. Some databases leave the value empty, others substitute a number that can easily be recognized (for example -9999). In `pandas` these values need to be converted to *Not A Number* using the `NaN` value of the `numpy package` (both `NaN` and `nan` work). In the code below, the value with index 5 in the `test1` column is changed to `NaN`. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `hist` function of `pandas` does not have the option to draw a cumulative distribution, unfortunatly. For that, we have to go back to the `hist` function of `matplotlib`. That gives another problem, as the `hist` function of `matplotlib` can not handle `nan` values. Luckily, the `pandas` package includes the function `dropna`, which drops all `nan` values from a column of a `DataFrame`, so that the cumulative distribution can be plotted with the `plt.hist` function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.test1[5] = np.NaN  # Replace the value with index 5 to NaN\n",
      "# Try the following function without the dropna function and see that you get an error\n",
      "plt.hist(data.test1.dropna(), cumulative=True, histtype='step', normed=True, align='right')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`pandas` also draws nice boxplots of a DataFrame"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.boxplot();"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The histgram or boxplot of one column of a DataFrame may be obtained by specifying the column you want to plot"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure()\n",
      "data.hist(column='test1')  # Makes histogram of column test1\n",
      "plt.figure()\n",
      "data. boxplot(column='test2');  # Makes boxplot of column test2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is time to start applying our statistical techniques to real data rather than datasets generated with a random number generator."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<figure>\n",
      "<img src= \"http://upload.wikimedia.org/wikipedia/commons/thumb/8/8f/Pseudotsuga_menziesii_28236.JPG/450px-Pseudotsuga_menziesii_28236.JPG\" width=\"200\" ALIGN=\"right\" style=\"padding:10px;\"> \n",
      "</figure>\n",
      "###Dataset of experiments on wooden beams\n",
      "A data set of 356 experiments on wooden beams, Douglas fir to be specific (see picture on right), is provided in the file `douglas_data.csv` (data courtesy Geert Ravenhorst, Timber Structures, Civil Engineering and Geosciences, TU Delft). The file contains 9 columns separated by commas. The first line (line number 0) of the file contains the names of the columns. The second line (line number 1) contains information about the units of the data (we won't load this information).  The first column has the name of the sample (`sample`), followed by: the moisture percentage (`moisture`), the knot ratio (`knotratio`), the tree ring width in mm (`treering`), the dynamic elasticity modulus in N/mm$^2$ (`Edyn`), the density of the wood in kg/m$^3$ (`density`), the beam height in mm (`beamheight`), the static elasticity modulus in N/mm$^2$ (`Estat`), and finally the bending strength in N/mm$^2$ (`bstrength`). A more extensive description of these different data is given when they are used. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Exercise 3. <a name=\"back3\"></a>Loading experimental data and basic operations\n",
      "Load the data in the file `douglas_data.csv` using the `read_csv` command of the `pandas` package (refer to `notebook5` for an introduction into `pandas`). Use the `skiprows` and `skipinitialspace` keywords. Carry out the following three tasks:\n",
      "\n",
      "* Determine and report the minimum and maximum measured values of the bending strength. \n",
      "* Determine and report the mean and standard deviation of the density. \n",
      "* Determine and report the 2.5, 50, and 97.5 percentiles of the tree ring width."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#ex3answer\">Answers to Exercise 3</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Exercise 4. <a name=\"back4\"></a>Boxplot of moisture content\n",
      "The moisture content is defined as the mass of moisture in a beam divided by the total mass of the beam (including the moisture) and is recorded as a percentage. Compute and report the mean and standard deviation of the moisture content, and make a box plot."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When you look at the data, it is obvious that there is one outlier. Create a new boxplot for all the data except for the one outlier, for example by making a boxplot for all moisture data below a certain value. Make sure you choose correct limits for the vertical axis, so that the whiskers are visible."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#ex4answer\">Answers to Exercise 4</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Exercise 5. <a name=\"back5\"></a>Histogram of bending strength\n",
      "Create a histogram of the bending strength. Add labels to the axes. Does the histogram look like a Normal distribution? On the same graph draw a red vertical line for the experimentally determined 5% bending strength. Print the 5 percentile bending strength to the screen."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#ex5answer\">Answers to Exercise 5</a>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Exercise 6. <a name=\"back6\"></a>Normal distribution for bending strength\n",
      "Let's try to fit a normal distribution to the bending strength data. This is obviously not quite correct, as the tail of the Normal distribution will extend below zero to the left, which is unrealistic. If the part of the tail below zero is small, it may be a reasonable first step. Create a normalized histogram of the bending strength. Compute the mean and standard deviation of the bending strength data and plot on the same graph the Normal probability density function using these estimates of the mean and standard deviation. Add a red vertical line for the 5% bending strength according to the data, and a black vertical line for the 5% bending strength according to the fitted Normal distribution"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#ex6answer\">Answers to Exercise 6</a>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Answers to the exercises"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a name=\"ex1answer\">Answers to Exercise 1</a>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats import norm\n",
      "mu = 100.0\n",
      "sig = 10.0\n",
      "data = sig * rnd.standard_normal(1000) + mu\n",
      "print 'mean of data is: ',np.mean(data)\n",
      "print 'standard devaiation of data is: ',np.std(data)\n",
      "plt.subplot(211)\n",
      "a = plt.hist(data, bins = 20, range = (50,150), normed=True)\n",
      "x = np.linspace(50,150,100)\n",
      "y = norm.pdf(x,mu,sig)\n",
      "plt.plot(x,y,'r')\n",
      "plt.xlim(50,150)\n",
      "plt.ylabel('probability')\n",
      "plt.subplot(212)\n",
      "b = plt.hist(data, bins = 20, range = (50,150), cumulative = True, histtype='step', normed = True, align='right')\n",
      "y = norm.cdf(x,mu,sig)\n",
      "plt.plot(x,y,'r')\n",
      "plt.xlim(50,150)\n",
      "plt.xlabel('bins')\n",
      "plt.ylabel('probability')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#back1\">Back to Exercise 1</a>\n",
      "\n",
      "<a name=\"ex2answer\">Answers to Exercise 2</a>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mu = 20.0\n",
      "sig = 4.0\n",
      "lower_theoretical = mu - 0.675 * sig\n",
      "upper_theoretical = mu + 0.675 * sig\n",
      "print 'theoretical IQR: ',lower_theoretical,upper_theoretical\n",
      "data = sig * rnd.standard_normal(1000) + mu\n",
      "lower, upper = np.percentile(data,[25,75])\n",
      "print 'IQR of data ',lower,upper\n",
      "plt.hist(data, bins = 20, cumulative = True, histtype='step')\n",
      "plt.axvline(lower,color='r')\n",
      "plt.axvline(upper,color='r')\n",
      "plt.axvline(lower_theoretical,color='k')\n",
      "plt.axvline(upper_theoretical,color='k')\n",
      "plt.xlabel('bins')\n",
      "plt.ylabel('cumulative number of data points')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#back2\">Back to Exercise 2</a>\n",
      "\n",
      "<a name=\"ex3answer\">Answers to Exercise 3</a>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pandas import read_csv\n",
      "w = read_csv('douglas_data.csv',skiprows=[1],skipinitialspace=True)\n",
      "print 'min and max bending strength: ', w.bstrength.min(), w.bstrength.max()\n",
      "print 'mean and std of density: ', w.density.mean(), w.density.std()\n",
      "print '2.5%, 50%, 97.5% tree ring width: ', np.percentile(w.treering,[2.5,50,97.5])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pandas import read_csv\n",
      "w = read_csv('douglas_data.csv',skiprows=[1],skipinitialspace=True)\n",
      "print '2.5%, 50%, 97.5% tree ring width: ', w.treering.describe(percentiles=[0.025,0.5,0.975])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#back3\">Back to Exercise 3</a>\n",
      "\n",
      "<a name=\"ex4answer\">Answers to Exercise 4</a>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'mean moisture content: ', w.moisture.mean()\n",
      "print 'standard deviation of moisture content: ', w.moisture.std()\n",
      "plt.boxplot(w.moisture)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.boxplot(w.moisture[w.moisture < 30])\n",
      "plt.ylim(10.5,17)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#back4\">Back to Exercise 4</a>\n",
      "\n",
      "<a name=\"ex5answer\">Answers to Exercise 5</a>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist(w.bstrength)\n",
      "plt.xlabel('bending strength (N/m$^2$)')\n",
      "five = np.percentile(w.bstrength,5)\n",
      "print '5 empirical percentile: ',five\n",
      "plt.axvline(five,color='r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#back5\">Back to Exercise 5</a>\n",
      "\n",
      "<a name=\"ex6answer\">Answers to Exercise 6</a>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats import norm\n",
      "plt.hist(w.bstrength,normed=True)\n",
      "# alternative\n",
      "# w.hist(column='bstrength',normed=True)\n",
      "meanstrength = w.bstrength.mean()\n",
      "stdstrength = w.bstrength.std()\n",
      "x = np.linspace(0,100,100)\n",
      "y = norm.pdf(x,loc=meanstrength,scale=stdstrength)\n",
      "plt.plot(x,y,'r')\n",
      "plt.axvline(five, color='r')\n",
      "plt.axvline(meanstrength - 1.64*stdstrength, color='k')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#back6\">Back to Exercise 6</a>"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}